{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNB442ZMXSTZgYymvqr2ZUD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKO71i82MDno","executionInfo":{"status":"ok","timestamp":1749548058145,"user_tz":-420,"elapsed":18000,"user":{"displayName":"Natawin Techawatcharapaikul","userId":"10261749973970121196"}},"outputId":"39e6d7f6-d3c8-4cfa-8a96-db53b4b4cd11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import os\n","import shutil\n","import pandas as pd\n","from pathlib import Path\n","\n","# ========== CONFIG ==========\n","dataset_root = \"/content/drive/MyDrive/Final Spectrogram/Gray/GraySpectrogram_10_Sec_trim\"\n","output_root = \"/content/drive/MyDrive/Final Spectrogram/Gray/Lebel_10_Sec_trim\"\n","output_image_dir = os.path.join(output_root, \"all_images\")\n","output_csv_path = os.path.join(output_root, \"labels.csv\")\n","os.makedirs(output_image_dir, exist_ok=True)\n","\n","valves = [\"mitral\", \"aortic\", \"tricuspid\", \"pulmonary\"]\n","splits = [\"train\", \"val\", \"test\"]\n","\n","records = []\n","\n","# ========== LOOP ‡∏ó‡∏∏‡∏Å Valve ==========\n","for valve in valves:\n","    dataset_path = os.path.join(dataset_root, f\"dataset_{valve}\")\n","    for split in splits:\n","        for label_folder in [\"Normal\", \"Abnormal\"]:\n","            label = 0 if label_folder == \"Normal\" else 1\n","            image_dir = os.path.join(dataset_path, split, label_folder)\n","            if not os.path.exists(image_dir): continue\n","\n","            for fname in os.listdir(image_dir):\n","                if not fname.endswith(\".png\"): continue\n","\n","                src = os.path.join(image_dir, fname)\n","                new_fname = f\"{valve}_{split}_{label}_{fname}\"\n","                dst = os.path.join(output_image_dir, new_fname)\n","                shutil.copy(src, dst)\n","\n","                records.append({\n","                    \"filename\": new_fname,\n","                    \"valve\": valve,\n","                    \"label\": label,\n","                    \"split\": split\n","                })\n","\n","# ========== SAVE CSV ==========\n","df = pd.DataFrame(records)\n","df.to_csv(output_csv_path, index=False)\n","print(f\"‚úÖ Saved labels.csv with {len(df)} records\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FBEl-kRMYfI","executionInfo":{"status":"ok","timestamp":1749548321562,"user_tz":-420,"elapsed":165221,"user":{"displayName":"Natawin Techawatcharapaikul","userId":"10261749973970121196"}},"outputId":"f945e617-24e9-445d-cf37-1c9d7ee6b35f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Saved labels.csv with 1115 records\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import torch\n","\n","valve_to_idx = {\"mitral\": 0, \"aortic\": 1, \"tricuspid\": 2, \"pulmonary\": 3}\n","\n","class HeartValveDataset(Dataset):\n","    def __init__(self, csv_file, image_dir, split, transform=None):\n","        import pandas as pd\n","        self.df = pd.read_csv(csv_file)\n","        self.df = self.df[self.df[\"split\"] == split].reset_index(drop=True)\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        image_path = os.path.join(self.image_dir, row[\"filename\"])\n","        image = Image.open(image_path).convert(\"L\")  # grayscale\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        valve_idx = valve_to_idx[row[\"valve\"]]\n","        label = torch.tensor([row[\"label\"]], dtype=torch.float32)\n","        return image, valve_idx, label\n"],"metadata":{"id":"JCZ7vXqKMqKf","executionInfo":{"status":"ok","timestamp":1749548423354,"user_tz":-420,"elapsed":6236,"user":{"displayName":"Natawin Techawatcharapaikul","userId":"10261749973970121196"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","\n","class MultiValveCNN(nn.Module):\n","    def __init__(self, num_valves=4):\n","        super().__init__()\n","        self.embedding = nn.Embedding(num_valves, 16)  # valve ‚Üí vector\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),  # image ‚Üí feature\n","            nn.Linear(32 * 56 * 56 + 16, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 1)  # binary output\n","        )\n","\n","    def forward(self, x, valve_idx):\n","        x_feat = self.cnn(x)                         # [B, 32, 56, 56]\n","        v_feat = self.embedding(valve_idx)           # [B, 16]\n","        x_feat = torch.flatten(x_feat, 1)            # [B, flat]\n","        all_feat = torch.cat((x_feat, v_feat), dim=1)\n","        out = self.fc(all_feat)\n","        return out\n"],"metadata":{"id":"hmGehO2GNNy5","executionInfo":{"status":"ok","timestamp":1749548426180,"user_tz":-420,"elapsed":13,"user":{"displayName":"Natawin Techawatcharapaikul","userId":"10261749973970121196"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","from torch.utils.data import DataLoader\n","\n","# ========== CONFIG ==========\n","BATCH_SIZE = 32\n","IMAGE_SIZE = (224, 224)\n","CSV_PATH = \"/content/drive/MyDrive/Final Spectrogram/Gray/Lebel_10_Sec_trim/labels.csv\"\n","IMAGE_DIR = \"/content/drive/MyDrive/Final Spectrogram/Gray/Lebel_10_Sec_trim/all_images\"\n","\n","# ========== TRANSFORM ==========\n","transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])  # grayscale\n","])\n","\n","# ========== LOAD DATA ==========\n","train_set = HeartValveDataset(CSV_PATH, IMAGE_DIR, split=\"train\", transform=transform)\n","val_set   = HeartValveDataset(CSV_PATH, IMAGE_DIR, split=\"val\", transform=transform)\n","test_set  = HeartValveDataset(CSV_PATH, IMAGE_DIR, split=\"test\", transform=transform)\n","\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n"],"metadata":{"id":"CP2aseFNNRDY","executionInfo":{"status":"ok","timestamp":1749548487557,"user_tz":-420,"elapsed":7661,"user":{"displayName":"Natawin Techawatcharapaikul","userId":"10261749973970121196"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","\n","# ========== SETUP ==========\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MultiValveCNN().to(device)\n","\n","# ========== LOSS FUNCTION WITHOUT POS_WEIGHT ==========\n","criterion = nn.BCEWithLogitsLoss()  # ‡πÑ‡∏°‡πà‡∏°‡∏µ pos_weight\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","EPOCHS = 20\n","\n","# ========== TRACK METRICS ==========\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","\n","# ========== TRAINING ==========\n","for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss, correct, total = 0.0, 0, 0\n","\n","    # Training loop\n","    for images, valve_idx, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n","        images, valve_idx, labels = images.to(device), valve_idx.to(device), labels.to(device)\n","\n","        outputs = model(images, valve_idx)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * images.size(0)\n","\n","        preds = torch.sigmoid(outputs) > 0.5\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_acc = correct / total\n","    avg_loss = total_loss / total\n","\n","    # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≠ epoch (Training)\n","    train_losses.append(avg_loss)\n","    train_accuracies.append(train_acc)\n","\n","    print(f\"‚úÖ Epoch {epoch+1}: Train Loss = {avg_loss:.4f} | Train Acc = {train_acc:.4f}\")\n","\n","    # ========== VALIDATION ==========\n","    model.eval()  # Set the model to evaluation mode\n","    val_loss, val_correct, val_total = 0.0, 0, 0\n","\n","    with torch.no_grad():  # Disable gradient computation for validation\n","        for images, valve_idx, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{EPOCHS}\"):\n","            images, valve_idx, labels = images.to(device), valve_idx.to(device), labels.to(device)\n","\n","            outputs = model(images, valve_idx)\n","            loss = criterion(outputs, labels)\n","\n","            val_loss += loss.item() * images.size(0)\n","\n","            preds = torch.sigmoid(outputs) > 0.5\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_acc = val_correct / val_total\n","    avg_val_loss = val_loss / val_total\n","\n","    # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≠ epoch (Validation)\n","    val_losses.append(avg_val_loss)\n","    val_accuracies.append(val_acc)\n","\n","    print(f\"‚úÖ Epoch {epoch+1}: Val Loss = {avg_val_loss:.4f} | Val Acc = {val_acc:.4f}\")\n","\n","    # ========== SAVE MODEL ==========\n","    model_save_path = f\"/content/drive/MyDrive/Final Spectrogram/Final Model/Gray_CNN_Data_Pretrain_model_epoch_{epoch+1}.pt\"\n","    torch.save(model.state_dict(), model_save_path)\n","    print(f\"üíæ Saved model at epoch {epoch+1} to {model_save_path}\")\n"],"metadata":{"id":"w-oQ8N0GOhMA"},"execution_count":null,"outputs":[]}]}
